{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### dependencies","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-22T09:12:19.569159Z","iopub.execute_input":"2021-10-22T09:12:19.569428Z","iopub.status.idle":"2021-10-22T09:12:19.594195Z","shell.execute_reply.started":"2021-10-22T09:12:19.569398Z","shell.execute_reply":"2021-10-22T09:12:19.593458Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport pickle\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom tensorflow.keras import optimizers\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-22T22:35:20.643971Z","iopub.execute_input":"2021-10-22T22:35:20.644482Z","iopub.status.idle":"2021-10-22T22:35:26.172687Z","shell.execute_reply.started":"2021-10-22T22:35:20.644367Z","shell.execute_reply":"2021-10-22T22:35:26.171944Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### creating the dataset","metadata":{}},{"cell_type":"code","source":"path = '../input/amazonsatelliteimages/train-jpg/train-jpg'\n\nfor img in os.listdir(path):\n    img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n    plt.imshow(img_arr)\n    # printing one image\n    break","metadata":{"execution":{"iopub.status.busy":"2021-10-22T22:35:26.174224Z","iopub.execute_input":"2021-10-22T22:35:26.174494Z","iopub.status.idle":"2021-10-22T22:35:27.396884Z","shell.execute_reply.started":"2021-10-22T22:35:26.174452Z","shell.execute_reply":"2021-10-22T22:35:27.396124Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nIMG_SIZE = 50\n\ntrain_data = []\n\ndef create_train_data():\n\n    for img in os.listdir(path):\n        \n        try:\n            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n            new_img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n            train_data.append(new_img_arr)\n        except Exception as e:\n            print(e)\n        \ncreate_train_data()","metadata":{"execution":{"iopub.status.busy":"2021-10-22T22:35:27.397867Z","iopub.execute_input":"2021-10-22T22:35:27.398059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('../input/planet-understanding-the-amazon-from-space/train_v2.csv/train_v2.csv')\n\nX = np.array(train_data)\ny = pd.DataFrame(labels['tags'])\n\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### encoding output variable","metadata":{}},{"cell_type":"code","source":"encode = LabelEncoder().fit(y)\nencoded_y = encode.transform(y)\ny = np_utils.to_categorical(encoded_y)\n\npickle.dump(X, open('./X.pkl','wb'))\npickle.dump(y, open('./y.pkl','wb'))\n\ny.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### creating the model","metadata":{}},{"cell_type":"code","source":"train_X = pickle.load(open('./X.pkl', 'rb'))\ntrain_y = pickle.load(open('./y.pkl', 'rb'))\n\n# normalizing features\ntrain_X = train_X/255.0\n\nn_epochs = 70\nb_size = 1300\n\nmodel = Sequential()\n# ADDING LAYERS\n\n# input layer\nmodel.add(Conv2D(64, (3, 3), input_shape=train_X.shape[1:]))\n# model.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128, (3, 3)))\n# model.add(Conv2D(128, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n# model.add(Conv2D(256, (3, 3)))\n# # model.add(Conv2D(256, (3, 3)))\n# # model.add(Conv2D(256, (3, 3)))\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Conv2D(512, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n\n# output neuron\nmodel.add(Flatten())\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dense(4096,activation=\"relu\"))\n\nmodel.add(Dense(449))\nmodel.add(Activation('softmax'))\n\nopt = optimizers.Adam(lr=1e-4)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### training the model","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = model.fit(train_X, train_y, epochs=n_epochs, batch_size=b_size, validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### creating test set","metadata":{}},{"cell_type":"code","source":"path = '../input/amazonsatelliteimages/test-jpg/test-jpg'\ntest_set = []\n\ndef create_test_data():\n\n    for img in os.listdir(path):\n        \n        try:\n            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n            new_img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n            test_set.append(new_img_arr)\n        except Exception as e:\n            print(e)\n        \ncreate_test_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### calculating fbeta score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(train.history['loss'], 'blue')\nplt.plot(train.history['val_loss'], 'red')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### making predictions","metadata":{}},{"cell_type":"code","source":"model.predict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}